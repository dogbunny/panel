{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any\n",
    "\n",
    "from panel.io.mime_render import exec_with_return\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import openai\n",
    "from panel.widgets import ChatInterface, ChatEntry\n",
    "\n",
    "pn.extension(\"perspective\")\n",
    "\n",
    "DATAFRAME_PROMPT = \"\"\"\n",
    "    Here are the columns in your DataFrame: {columns}.\n",
    "    Create  a plot with hvplot that highlights an interesting\n",
    "    relationship between the columns with hvplot groupby kwarg.\n",
    "\"\"\"\n",
    "\n",
    "CODE_REGEX = re.compile(r\"```python(.*?)```\", re.DOTALL)\n",
    "\n",
    "USER = \"User\"\n",
    "PLOT_ASSISTANT=\"Plot Assistant\"\n",
    "CODE_ASSISTANT=\"Code Assistant\"\n",
    "\n",
    "async def respond_with_openai(contents: Any):\n",
    "    # extract the DataFrame\n",
    "    if isinstance(contents, pd.DataFrame):\n",
    "        global df\n",
    "        df = contents\n",
    "        columns = contents.columns\n",
    "        message = DATAFRAME_PROMPT.format(columns=columns)\n",
    "    else:\n",
    "        message = contents\n",
    "\n",
    "    # ask OpenAI to plot\n",
    "    response = await openai.ChatCompletion.acreate(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        temperature=0,\n",
    "        max_tokens=500,\n",
    "        stream=True,\n",
    "    )\n",
    "    message = \"\"\n",
    "    async for chunk in response:\n",
    "        message += chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "        yield {\"user\": CODE_ASSISTANT, \"value\": message}\n",
    "\n",
    "\n",
    "async def respond_with_executor(code: str):\n",
    "    value = exec_with_return(code=code, global_context=globals())\n",
    "    return ChatEntry(user=PLOT_ASSISTANT, value = value)\n",
    "\n",
    "\n",
    "async def response_callback(\n",
    "    contents: Any,\n",
    "    user: str,\n",
    "    instance: ChatInterface,\n",
    "):\n",
    "    if user == USER:\n",
    "        async for chunk in respond_with_openai(contents):\n",
    "            yield chunk\n",
    "        instance.respond()\n",
    "    elif user==CODE_ASSISTANT and CODE_REGEX.search(contents):\n",
    "        yield await respond_with_executor(CODE_REGEX.search(contents).group(1))\n",
    "    else:\n",
    "        yield \"Sorry. I don't know how to respond to this\"\n",
    "\n",
    "# https://raw.githubusercontent.com/holoviz/panel/main/examples/assets/occupancy.csv\n",
    "chat_interface = ChatInterface(\n",
    "    callback=response_callback, widgets=[pn.widgets.TextAreaInput(name=\"Text\"), pn.widgets.FileInput(name=\"Upload\")], height=800\n",
    ")\n",
    "chat_interface.servable()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
